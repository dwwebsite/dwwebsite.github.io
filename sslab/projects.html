
<!DOCTYPE html>
<html lang="en">
<head>
    <title>The Social Sensing Lab</title>
    <!-- Meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">    
    <link rel="shortcut icon" href="favicon.ico">  
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700' rel='stylesheet' type='text/css'>    
    <!-- FontAwesome JS-->
    <script defer src="https://use.fontawesome.com/releases/v5.8.1/js/all.js" integrity="sha384-g5uSoOSBd7KkhAMlnQILrecXvzst9TdC09/VM+pjDTCM+1il8RHz5fKANTFFb+gQ" crossorigin="anonymous"></script>
    <!-- Global CSS -->
    <link rel="stylesheet" href="assets/plugins/bootstrap/css/bootstrap.min.css">   
    <!-- Plugins CSS -->    
    <link rel="stylesheet" href="assets/plugins/flexslider/flexslider.css"> 
    <!-- Theme CSS -->  
    <link id="theme-style" rel="stylesheet" href="assets/css/theme-1.css">
    <style type="text/css">

.center-fit{
  width: 50vw;
  height: 40vw;
  max-width: 300px;
  max-height: 240px;
  display: block;
  margin: auto;
  margin-bottom: 30px !important;
}
a{
    text-decoration: underline !important;
}

h1 {
  font-size: 2rem !important;

}


.nav-link{  font-size: 1.1rem !important;
}

h2 {
  font-size: 1.6rem !important;

}


.h1 {
  font-size: 2rem !important;

}


#topnav {
   display: none !important;

}


@media  (max-width: 540px){
#wrap{
max-width: 90% !important;
text-align: left; 

}
#topnav {
   display: block !important;
     position:fixed !important;
    width:100% !important;
    z-index: 1000000 !important;
    top:0 !important;

}
li {font-size:1rem !important; } /*1rem = 16px*/
   

p {font-size:1rem !important; } /*1rem = 16px*/


ul {line-height:1.2rem !important;}

h1 {
  font-size: 1.8rem !important;

}

h2 {
  font-size: 1.5rem !important;

}
.edit {
  font-size: 1.1rem !important;

}

.edit2 {
  font-size: 1.2rem !important;

}

.edit3 {
  font-size: 1.2rem !important;

}

#topnav {
   display: block !important;

}
#midnav {
   display: none !important;

}


.navedit {
    font-size: 1rem !important;

}


img{
    margin-top:40px !important
}
#nd {
   display: none !important;

}

}







</style>
</head>	

<body class="home-page">
    <div class="wrapper" id="wrap">


<div class="main-nav-wrapper"  id= "topnav">
            <div class="container">
                <nav class="main-nav navbar navbar-expand-md navbar-fixed-top" role="navigation">    
                    <button class="navbar-toggler collapsed" type="button" data-toggle="collapse" data-target="#navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button><!--//nav-toggle-->
                    <div class="navbar-collapse collapse" id="navbar-collapse">
                        <ul class="nav navbar-nav">
                            <li class="nav-item"><a class="active nav-link" href="index.html">Home</a></li>
                   
                            <li class="nav-item"><a class=" nav-link" href="projects.html">Research</a></li>

                            <li class="nav-item"><a class=" nav-link" href="team.html">Members</a></li>

                            <li class="nav-item"><a class="nav-link" href="publications.html">Publications</a></li>

                                                </ul><!--//nav-->
                    </div><!--//navabr-collapse-->
                </nav><!--//main-nav-->
            </div><!--//container-->
        </div><!--//main-nav-container-->

        <!-- ******HEADER****** --> 
        <header class="header">  
           
            <div class="header-main container" style="margin-left: 10% !important; min-width: 80% !important;margin-right: 10% !important;">
                <div class="row">
                    <h1 class="logo col-md-4 col-12">
                        <a href="index.html"><img id="logo" src="assets/images/logo.png" alt="Logo"></a>
                    </h1><!--//logo-->           
                    <div class="info col-md-8 col-12 ">
                    <div class="float-right">
                                                <a href="https://cse.nd.edu/"><img id="nd" src="assets/images/NotreDame.png" alt="NotreDame"></a>
</div>
                    </div><!--//info-->
                </div><!--//row-->
            </div><!--//header-main-->
        </header><!--//header-->
        <!-- ******NAV****** -->
     <div class="main-nav-wrapper" id="midnav">
            <div class="container">
                <nav class="main-nav navbar navbar-expand-md" role="navigation">    
                    <button class="navbar-toggler collapsed" type="button" data-toggle="collapse" data-target="#navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button><!--//nav-toggle-->
                    <div class="navbar-collapse collapse" id="navbar-collapse">
                        <ul class="nav navbar-nav">
                            <li class="nav-item"><a class=" nav-link" href="index.html">Home</a></li>
                   
                            <li class="nav-item"><a class="active nav-link" href="projects.html">Research</a></li>

                            <li class="nav-item"><a class=" nav-link" href="team.html">Members</a></li>

                            <li class="nav-item"><a class="nav-link" href="publications.html">Publications</a></li>

                                                </ul><!--//nav-->
                    </div><!--//navabr-collapse-->
                </nav><!--//main-nav-->
            </div><!--//container-->
        </div><!--//main-nav-container-->
        <!-- ******CONTENT****** --> 
        <div class="content container" style="margin-left: 7% !important; min-width: 86% !important;margin-right: 7% !important;">
            <div class="page-wrapper">
                <header class="page-heading clearfix">
                    <h1 class="heading-title float-left">Research Projects</h1>
                    <div class="breadcrumbs float-left">
                        <ul class="breadcrumbs-list">
                            <li class="breadcrumbs-label">You are here:</li>
                            <li><a href="index.html">Home</a><i class="fas fa-angle-right"></i></li>
                            <li class="current">Research</li>
                        </ul>
                    </div><!--//breadcrumbs-->
                </header> 
                <div class="page-content">    
                    <div class="page-row section-heading" style="color:black !important">



<p style="font-size:18px;">
The primary research focus of the lab lies in the emerging area of <b> Social Sensing and Cyber-Physical Systems in Social Spaces</b>, where data are collected from human sources or devices on their behalf. Social sensing systems are one example of information distillation systems in current era of <i>Big Data</i>. We carreid out a set of projects to address several key challenges in social sensing and I beleived the theories, algorithms, frameworks and systems developed in these projects are useful in building future information distillabtion systems in general. An overview of social sensing can be found in  <a href="./pdf/computer-18.pdf"> <b> IEEE Computer Perspective Paper</b></a>. </p> 
                    </div>
                    
       

<table class="table-project">
<col align="left" />
<col align="right" />

<tr>
<td>
<h2>CrowdLearn: A Crowd-AI Hybrid System for Deep Learning-based Applications</h2> <br>
<p style="font-size:18px;">
Artificial Intelligence (AI) has been widely adopted in many important application domains such as speech recognition, computer vision, autonomous driving, and AI for social good. While AI algorithms often significantly reduce the detection time and labor cost in many applications, their performance sometimes falls short of the desired accuracy and is considered to be less reliable than domain experts. To exacerbate the problem, the black-box nature of the AI algorithms also makes it difficult to troubleshoot the system when their performance is unsatisfactory. The emergence of crowdsourcing platforms (e.g., Amazon Mechanic Turk, Waze) brings about the opportunity to incorporate human intelligence into AI algorithms. However, the crowdsourcing platform is also black-box in terms of the uncertain response delay and crowd worker quality. In this project, we develop the CrowdLearn, a crowd-AI hybrid system that leverages the crowdsourcing platform to troubleshoot, tune, and eventually improve the blackbox AI algorithms by welding crowd intelligence with machine intelligence. The system is specifically designed for deep learningbased damage assessment (DDA) applications where the crowd tend to be more accurate but less responsive than machines. The results have been published in <a href="./pdf/icdcs19.pdf"> <b>IEEE ICDCS 2019</b> </a>. 
</p>
</p>
</td>
</tr>

<tr>
<td>
  <img class="center-fit" src="./pic/crowdai.jpg", alt="Social Sensing",  width="320" height="250" /> </td>
</tr>

</table>
<br>

                        
<table class="table-project">
<col align="left" />
<col align="right" />

<tr>
<td>
<h2>Towards Reliable and Optimized Crowdsensing based Cyber-Physical Systems (C-CPS) </h2> <br>
<p style="font-size:18px;">
This project is motivated by the challenges in data and predictive analytics and in control for participatory science data collection and curation (known as crowdsensing) in cyber-physical systems (CPS).  This project focuses on data-driven frameworks to address these challenges in CPS-enabled participatory science that builds on statistics, optimization, control, and natural language processing. Our framework tightly combines the underlying methods and techniques, especially focusing on physical sensors, mobility, and model-based approaches, to improve efficiency, effectiveness, and accountability. This project also closely integrates education and training with foundational research and public outreach that enhances interdisciplinary thinking about CPS systems, engages the public through participatory science, and broadens participation in science, technology, engineering, mathematics, and computer science.
</p>
</td>
</tr>

<tr>
<td>
  <img class="center-fit" src="./pic/hcps.png", alt="Social Sensing",  width="320" height="250" /> </td>
</tr>

</table>
<br>





<table class="table-project">
<col align="left" />
<col align="right" />


<tr>
<td>
<h2>SocialDrone: An Integrated Social Media and Drone Sensing System for  Reliable Disaster Response</h2> <br>
<p style="font-size:18px;">
Social media sensing has emerged as a new disaster response application paradigm to collect real-time observations from online social media users about the disaster status. Due to the noisy nature of social media data, the task of identifying trustworthy information (referred to as "truth discovery") has been a crucial task in social media sensing.  In this project, we develop SocialDrone, a novel closed-loop social-physical active sensing framework that integrates social media and unmanned aerial vehicles (UAVs) for reliable disaster response applications. In SocialDrone, signals emitted from the social media are distilled to drive the drones to target areas to verify the emergency events. The verification results are then taken back to improve the sensing and distillation process on social media. The SocialDrone framework introduces several unique challenges: i) how to drive the drones  using the unreliable social media signals? ii) How to ensure the system is adaptive to the high dynamics from both the physical world and social media? iii) How to incorporate real-world constraints (e.g., the deadlines of events, limited number of drones) into the framework? The SocialDrone addresses these challenges by building a novel integrated social-physical sensing system that leverages techniques from game theory, constrained optimization, and reinforcement learning.  The results have been published in <a href="./pdf/infocom20.pdf"> <b>IEEE Infocom 2020</b> </a>. 
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/socialdrone.png", alt="Social Sensing",  width="320" height="220" /> </td>
</tr>
</table>
<br>


<table class="table-project">
<col align="left" />
<col align="right" />


<tr>
<td>
<h2>FauxBuster: A Content-Agnostic Fauxtography Detector using Social Media Comments</h2> <br>
<p style="font-size:18px;">
With the increasing popularity of online social media (e.g., Facebook, Twitter, Reddit), the detection of misleading content on social media has become a critical undertaking. This paper focuses on an important but largely unsolved problem: detecting fauxtography (i.e., social media posts with misleading images). We found that the existing literature falls short in solving this problem. In particular, current solutions either focus on the detection of fake images or misinformed texts of a social media post. However, they cannot solve our problem because the detection of fauxtography depends not only on the truthfulness of the images and the texts but also on the information they deliver together on the posts. In this project, we develop the FauxBuster, an end-to-end supervised learning system that can effectively track down fauxtography by exploring the valuable clues from user's comments of a post on social media. The FauxBuster is content-agnostic in that it does not rely on the analysis of the actual content of the images, and hence is robust against malicious uploaders who can intentionally modify the presentation and description of the images. We evaluate FauxBuster on two mainstream social media platforms - Reddit and Twitter. Results show that FauxBuster is both effective and efficient in addressing the fauxtography problem. The results have been published in <a href="./pdf/bigdata18-fb.pdf"> <b>IEEE BigData 2018 </b> </a>, <a href="./pdf/snam20.pdf"> <b>Springer SNAM 20 </b> </a>. 
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/fauxbuster.png", alt="Social Sensing",  width="320" height="250" /> </td>
</tr>
</table>
<br>


<table class="table-project">
<col align="left" />
<col align="right" />


<tr>
<td>
<h2>VisualPoet: Classical Poetry Recommendation with Visual Input on Social Media</h2> <br>
<p style="font-size:18px;">
With the increasing popularity of  portable devices with cameras (e.g., smartphones and tablets) and ubiquitous Internet connectivity, travelers can share their instant experience during the travel by posting photos they took to social media platforms. In this project, we develop a new image-driven poetry recommender system that takes a traveler's photo as input and recommends classical poems that can enrich the photo with aesthetically pleasing quotes from the poems.  Three critical challenges exist to solve this new problem: i) how to extract the implicit artistic conception embedded in both poems and images? ii) How to identify the salient objects in the image without knowing the creator's intent? iii) How to accommodate the diverse user perceptions of the image and make a diversified poetry recommendation?  The VisualPoet system  jointly addresses the above challenges by developing heterogeneous information network and neural embedding techniques. Evaluation results from real-world datasets and a user study demonstrate that our system can recommend highly relevant classical poems for a given photo and receive significantly higher user ratings compared to the state-of-the-art solutions. The results have been published in <a href="./pdf/asonam19-vp.pdf"> <b>ACM/IEEE ASONAM 2019</b> </a>. 
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/visualpoet.png", alt="Social Sensing",  width="320" height="250" /> </td>
</tr>
</table>
<br>


<table class="table-project">
<col align="left" />
<col align="right" />


<table class="table-project">
<col align="left" />
<col align="right" />


<tr>
<td>
<h2>TransLand: An Adversarial Transfer Learning Framework for Migratable Urban Land Usage Classification</h2> <br>
<p style="font-size:18px;">
Urban land usage classification is a critical task in big data based smart city applications that aim to understand the social-economic land functions and physical land attributes in urban environments. This project focuses on a migratable urban land usage classification problem using remote sensing data (i.e., satellite images). Our goal is to accurately classify the land usage of locations in a target city where the ground truth land usage data is not available by leveraging a classification model from a source city where such data is available. This problem is motivated by the limitation of current solutions that primarily rely on a rich set of ground-truth data for accurate model training, which encounters high annotation costs. In this project, we develop TransLand, an adversarial transfer learning framework to translate the satellite images from the target city to the source city for accurate land usage classification.
We evaluated our framework on the real-world satellite imagery and land usage datasets collected from different cities in Europe. The results show that TransLand significantly outperforms the state-of-the-art land usage classification baselines in classifying the land usage of locations in a city.  The results have been published in <a href="./pdf/bigdata19-tl.pdf"> <b>IEEE BigData 2019</b> </a>. 
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/transland.png", alt="Social Sensing",  width="320" height="250" /> </td>
</tr>
</table>
<br>

<table class="table-project">
<col align="left" />
<col align="right" />


<tr>
<td>
<h2>EdgeBatch: Towards AI-empowered Intelligent Edge Systems</h2> <br>
<p style="font-size:18px;">
WModern Internet of Things (IoT) systems are increasingly leveraging deep neural networks (DNNs) with the goal of enabling intelligence at the edge of the network. While applying DNNs can greatly improve the accuracy of autonomous decisions and inferences, a significant challenge is that DNNs are traditionally designed and developed for advanced hardware (e.g., GPU clusters) and can not easily meet the real time requirements when deployed in a resource-constrained edge computing environment. While many systems have been proposed to facilitate deep learning at the edge,  a key limitation lies in the under-utilization of the parallelizable GPU resources of edge nodes (e.g., IoT devices). In this project, we develop EdgeBatch, a collaborative intelligent edge computing framework that minimizes the delay and energy consumption of executing DNN tasks at the edge by sharing idle GPU resources among privately owned IoT devices. We implemented EdgeBatch on a real-world edge computing testbed that consists of heterogeneous IoT devices. The results show that EdgeBatch achieved significant performance gains in terms of both the end-to-end delay and energy savings compared to the state-of-the-art solutions. The results have been published in <a href="./pdf/rtss19.pdf"> <b>IEEE RTSS 2019</b> </a>, <a href="./pdf/infocom19.pdf"> <b>IEEE Infocom 2019</b> </a>. 
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/edgebatch.png", alt="Social Sensing",  width="320" height="250" /> </td>
</tr>
</table>
<br>


<tr>
<td>
<h2>StreamGuard: A Social Sensing Approach to Detecing the Copyright Infringement in Live Video Sharing Platforms</h2> <br>
<p style="font-size:18px;">
Copyright infringement detection is a critical problem in large-scale online video sharing systems: the copyright-infringing videos must be correctly identified and removed from the system to protect the copyright of the content owners.
This project focuses on a challenging problem of detecting copyright infringement in live video streams. The problem is particularly difficult because i) streamers can be sophisticated and modify the title or tweak the presentation of the video to bypass the detection system; ii) legal videos and copyright-infringing ones may have very similar visual content and descriptions. We found current commercial copyright detection systems did not address this problem well: a large amount of copyrighted content bypasses the detection system while legal streams are taken down by mistake. In this project, we develop the StreamGuard, a online video copyright infringement detection system that addresses the above challenges by leveraging live chat messages from the audience. We evaluated our system on real-world live video streams collected from YouTube. The results show that StreamGuard is effective and efficient in identifying the copyright-infringing videos. The results have been published in <a href="./pdf/bigdata18-sg.pdf"> <b>IEEE BigData 2018 </b> </a>, <a href="./pdf/asonam18-sg.pdf"> <b>ACM/ASONAM 2018</b></a>. 
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/streamguard.png", alt="Social Sensing",  width="320" height="250" /> </td>
</tr>
</table>
<br>


<table class="table-project">
<col align="left" />
<col align="right" />


<tr>
<td>
<h2>RiskSens: A Multi-view Learning Approach to Identifying Urban Traffic Risk using Social and Remote Sensing</h2> <br>
<p style="font-size:18px;">
With the ever-increasing number of road traffic accidents worldwide, the road traffic safety has become a critical problem in intelligent transportation systems. A key step towards improving the road traffic safety is to identify the locations where severe traffic accidents happen with a high probability so the precautions can be applied effectively. We refer to this problem as risky traffic location identification. While previous efforts have been made to address similar problems, two important limitations exist: i) data availability: many cities (especially in developing countries) do not maintain a publicly accessible database for the traffic accident records in a city, which makes it difficult to accurately estimate the accidents in the city; ii) location accuracy: many self-reported traffic accidents (e.g., social media posts from common citizens) are not associated with the exact GPS locations due to the privacy concerns. To address these limitations, this project develops the RiskSens, a multi-view learning approach to identifying the risky traffic locations in a city by jointly exploring the social and remote sensing data. We evaluated RiskSens using real world datasets from large cities. The evaluation results show that RiskSens significantly outperforms the state-of-the-art baselines in identifying risky traffic locations in a city.   
The results have been published in <a href="./pdf/bigdata18-rs.pdf"> <b>IEEE BigData 2018</b> </a>, <a href="./pdf/asonam19-rc.pdf"> <b>ACM/IEEE ASONAM 2019</b> </a>, <a href="./pdf/dcoss19-dr.pdf"> <b>IEEE DCoSS 2019</b> </a>. 
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/risksens.png", alt="Social Sensing",  width="320" height="250" /> </td>
</tr>
</table>
<br>


<table class="table-project">
<col align="left" />
<col align="right" />


<tr>
<td>
<h2>When Social Sensing meets Edge Computing</h2> <br>
<p style="font-size:18px;">
A key limitation in the current social sensing solution space is that data processing and analytic tasks are often done on a "backend" system (e.g., on dedicated servers or commercial clouds). Unfortunately, this scheme ignores the rich processing capability of increasingly powerful edge devices owned by individuals (e.g., mobile phones, tablets, smart wearables, and the Internet of Things). The advent of edge computing pushes the frontier of computation, service, and data along the cloud-to-things continuum to the edge of the network, and brings new opportunities for social sensing applications. By combining social sensing with edge computing, the privately owned edge devices not only serve as pervasive sensors, but also form a federation of computational nodes where the data collected from them can be processed and consumed at the edge.  We refer to the marriage of social sensing and edge computing as Social Sensing based Edge Computing paradigm (SSEC). In this project, we investigate several fundamental challenges in SSEC such as resource management, incentives design, robustness.
The results have been published in <a href="./pdf/rtas18.pdf"> <b>IEEE RTAS 2018</b> </a>, <a href="./pdf/sec18.pdf"> <b>ACM SEC 2018</b> </a>, <a href="./pdf/icccn-survey.pdf"> <b>IEEE ICCCN 2019</b></a>. 
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/edge.jpg", alt="Social Sensing",  width="320" height="250" /> </td>
</tr>
</table>
<br>





<table class="table-project">
<col align="left" />
<col align="right" />

<tr>
<td>
<h2>Scalable, Dynamic and Constraint-Aware Social Sensing System</h2> <br>
<p style="font-size:18px;">
While significant progress has been made to build reliable social sensing system, some important challenges have not been well addressed yet. First, existing social sensing systems did not fully solve the dynamic truth estimation problem where the ground truth of claims changes over time. Second, many current solutions are not scalable to large-scale social sensing events because of the centralized nature of their data analytics algorithms. Third, the transition of true values of measured variables is constrained by some physical rules that must be followed to ensure correct estimation. In this project, we developed a scalable streaming social sensing system with explicit considerations of the physical constraints on the measured variables to address the above challenges. We evaluated our framework through real world social sensing applications. The evaluation results show that our system is scalable and outperforms the state-of-the-art solutions in terms of both effectiveness and efficiency. The results have been published in <a href="./pdf/icdcs17.pdf"> <b>IEEE ICDCS 2017 </b> </a>, <a href="./pdf/bigdata17-1.pdf"> <b>IEEE BigData 2017</b></a>, <a href="./pdf/tbd18.pdf"> <b> IEEE Transanction on Big Data</b></a>. 
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/scalable.png", alt="Social Sensing",  width="320" height="250" /> </td>
</tr>
</table>
<br>



<table class="table-project">
<col align="left" />
<col align="right" />

<tr>
<td>
<h2>From Big Data to Small Data: Taming the two V's of Veracity and Variety</h2> <br>
<p style="font-size:18px;">
Data of questionable quality has led to significantly negative economic and social impacts on organizations, leading to overrun in costs, lost revenue, and decreased efficiencies. The issues on data reliability, credibility, and provenance has become even more daunting when dealing with the variety of data, especially data that are not directly collected by an organization, but from the third-party sources such as social media, data brokers, and crowdsourcing. To address such issues, this project aims to develop a <i> Data Valuation Engine (DVE) </i> that solves the critical problem of data reliability, credibility and provenance, and provides accountability and quality processes right from data acquisition. The DVE leverages and innovates techniques in estimation theory, data fusion and machine learning to fill a critical gap in data accountability and quality, thereby providing a transformative step in countering the ubiquitous data quality issues found in almost every application domain from business to environment to health to national security. The DVE will be integrated in the <i> Hadoop ecosystem </i> and will be agnostic to the data source, application or analytics, and provided as a hosted solution to the community. The results have been published in <a href="./pdf/bigdata16-c.pdf"> <b> IEEE BigData 16 </b> </a>, <a href="./pdf/recsys16.pdf"> <b> ACM Recsys 16 </b> </a>, <a href="./pdf/tbd17.pdf"> <b> IEEE Transanction on Big Data</b></a>. 
</p>
</td>
</tr>

<tr>
<td><img class="center-fit" src="./pic/bigdata.jpeg", alt="Social Sensing",  width="320" height="200" /> </td>
</tr>
</table>
<br>


<table class="table-project">
<col align="left" />
<col align="right" />

<tr>
<td>
<h2>Location-based Social Sensor Profiling</h2> <br>
<p style="font-size:18px;">
While many social sensing studies focus on sensing
and recovering the status of the physical world, this project investigates
the problem of profiling the social sensors (i.e., humans). In
particular, we study the problem of accurately inferring the localness and the home
locations of people from the noisy and sparse social sensing
data they contribute. In this study, we propose a new method to accurately infer the home locations of people by explicitly exploring the localness
of people and the dependency between people based on their
check-in behaviors under a rigorous analytical framework. We
perform extensive experiments to evaluate the performance of
our scheme and compared it to the state-of-the-art techniques
using three real world data traces collected from Foursquare.
The results showed the effectiveness of our scheme in accurately
profiling the home locations of people. The results have been published in <a href="./pdf/asonam16.pdf"> <b> IEEE ASONAM 16 </b></a>, <a href="./pdf/bigdata17-poi.pdf"> <b> IEEE BigData 17 </b></a>, <a href="./pdf/infocom17.pdf"> <b> IEEE INFOCOM 17 </b></a>, <a href="./pdf/asonam17.pdf"> <b> IEEE ASONAM 17 </b></a>.

</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/findme.jpeg", alt="Social Sensing",  width="320" height="200" /> </td>
</tr>
</table>
<br>


<table class="table-project">
<col align="left" />
<col align="right" />

<tr>
<td>
<h2>Social-aware Interesting Place Finding</h2> <br>
<p style="font-size:18px;">
This project studies an interesting place finding problem in social sensing,
in which the goal is to correctly identify the interesting places in a city (e.g., parks, museums, historic sites, scenic trails, etc.).
Important challenges exist in solving this problem: (i) the interestingness of a
place is not only related to the number of users who visit it, but also depends
upon the travel experience of the visiting users; (ii) the user's social connections
could directly affect their visiting behavior and the interestingness judgment
of a given place. In this project, we develop a new Social-aware Interesting
Place Finding framework that addresses the above challenges by
explicitly incorporating both the user's travel experience and social relationship
into a rigorous analytical framework. Our framework can find interesting
places not typically identified by traditional travel websites (e.g., TripAdvisor,
Expedia). We valid the effectiveness of our framework through
real-world datasets collected from location-based social network services. The results have been published in <a href="./pdf/smartcity15-c.pdf"> <b> IEEE Smart City 15 </b></a>, <a href="./pdf/dcoss16-c.pdf"> <b> IEEE DCoSS 16 </b></a>, <a href="./pdf/kbs17.pdf"> <b> Elsevier KBS </b></a>. 
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/interestingplace.png", alt="Social Sensing",  width="320" height="200" /> </td>
</tr>
</table>
<br>


<table class="table-project">
<col align="left" />
<col align="right" />

<tr>
<td>
<h2>Who to Choose: Source/Sensor Selection in Social Sensing</h2> <br>
<p style="font-size:18px;">
This project investigates a new problem of critical source selection in social sensing applications. The goal of this problem is to identify a subset of critical sources that can help effectively reduce the computational complexity of the information distillation problem and improve the accuracy of the analysis results. In this project, we propose a new scheme, Critical Source Selection (CSS), to find the critical set of sources by explicitly exploring both dependency and speak rate of sources. We evaluated the performance of our scheme and compared it to the state-of-the-art baselines using data traces collected from a real world social sensing application. The results showed that our scheme significantly outperforms the baselines by finding more truthful information at a higher speed. The results have been published in  <a href="./pdf/dcoss17.pdf"> <b> IEEE DCoSS 17 </b></a>, <a href="./pdf/kbs18.pdf"> <b> Elsevier KBS </b></a>. 
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/sensor-select.jpg", alt="Social Sensing",  width="320" height="200" /> </td>
</tr>
</table>
<br>

<table class="table-project">
<col align="left" />
<col align="right" />

<tr>
<td>
<h2>Truth Discovery in Social Sensing</h2> <br>
<p style="font-size:18px;">
This project solves a fundamental problem in information distillation in social sensing where data are collected from human sources or devices in their possession: how to ascertain the <i>credibility of information</i> and estimate <i>reliability of sources</i>, as the information sources are usually unvetted and potentially unreliable. We call this problem <i>truth discovery</i>. Current research in data mining and machine learning (e.g., fact-finding) solves similar problems with important limitations on analysis semantics and suboptimal solutions. In contrast, our research presented, for the first time, an <i>optimal</i> truth discovery framework and system that provides accurate and quantifiable conclusions on both information credibility and source reliability without prior knowledge on either. Our work provides a new generic foundation for distilling reliable and quantifiable information from unreliable sources (e.g., humans). The results have been published in <a href="./pdf/fusion11.pdf"> <b> Fusion 11 </b> </a>, <a href="./pdf/ipsn12.pdf"> <b> ACM/IEEE IPSN 12 </b> </a>, <a href="./pdf/tosn14.pdf"><b>ACM ToSN</b> </a>, <a href="./pdf/secon15.pdf"> <b> IEEE SECON 15</b>, </a> <a href="./pdf/icwsm16.pdf"> <b> ICWSM 16</b> </a>, <a href="./pdf/dcoss16-j.pdf"> <b> IEEE DCoSS 16</b>,</a> <a href="./pdf/mass17.pdf"> <b> IEEE MASS 17</b> </a>.
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/socialsensing2.jpg", alt="Social Sensing",  width="320" height="200" /> </td>
</tr>
</table>
<br>

<table class="table-project">
<col align="left" />
<col align="right" />

<tr>
<td>
<h2>Quality of Information (QoI) Assurance in Social Sensing</h2> <br>
<p style="font-size:18px;">
This project investigates another critical problem in social sensing: how to accurately assess the quality of the truth discovery results by quantifying estimation errors and providing confidence bounds. This guaranteed quality analysis is immensely important in any practical settings where errors have consequences. However, this is largely missing in current literature. We successfully derived the first performance bound that is able to accurately predict the estimation errors of the truth discovery results. Our work allows real world applications to assess the quality of data obtained from unreliable sources to a desired confidence level, in the absence of independent means to verify the data and in the absence of prior knowledge of reliability of sources.  Our work was mentioned explicitly in the <b> National Academies Press </b> as a "good example of Army's cross-genre research" in 2013. The research results have been published in <a href="./pdf/dmsn11.pdf"> <b> DMSN 11</b> </a>, <a href="./pdf/secon12.pdf"> <b> IEEE SECON 12</b> </a>, <a href="./pdf/jsac13.pdf"> <b> IEEE JSAC</b> </a>.
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/qoi2.jpeg", alt="QoI",  width="320" height="210" /> </td>
</tr>
</table>
<br>


<table class="table-project">
<col align="left" />
<col align="right" />

<tr>
<td>
<h2>Link Analysis across Multi-genre Networks</h2> <br>
<p style="font-size:18px;">
Social sensing data is generated through the complicated interactions of information, social and physical networks. The interdisciplinary network systems are so complex that link analysis across multi-genre networks is essential. However, link analysis taking into account the three networks altogether is rare in current research. 
In this project, we generalized the truth discovery framework to jointly analyze links across multi-genre networks and developed a new information distillation system, called Apollo. Apollo has been continuously tested through real world case studies using large-scale datasets collected from open source media and smart road applications. The results showed good correspondence between observations deemed correct by Apollo and ground truth, demonstrating the power of using link analysis across multi-genre networks for efficient information distillation. The results have been published in <a href="./pdf/rtss13.pdf"> <b>IEEE RTSS 13</b> </a>, <a href="./pdf/jrts-15.pdf"> <b>Journal of Real-time Systems</b> </a>.
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/multinet3.png", alt="Net",  width="320" height="250" /> </td>
</tr>
</table>
<br>

<!---
<table cellspacing="50"  >
<col align="left" />
<col align="right" />
<tr>    
<td><img src="./pic/rt5.png", alt="RT",  width="330" height="220" /> </td>


<td>
<h3>Real-Time Information Distillation from Streaming Data</h3> 
<p style="font-size:18px;">
Social sensing data usually come at such large volume and high speed (e.g., more than 200k tweets are uploaded to Twitter every minute) that they must be processed in real-time in order to maximize their value. However, the truth discovery studies in current research are mostly batch algorithms that generally cannot scale with the streaming data or do not exploit all data available.  In this project, we developed the first <i>on-line</i> truth estimation approach to determine the quality of information and the reliability of sources in <i>real-time</i> for social sensing applications. The results demonstrated that our approach was able to analyze the data at a speed 10-100 times faster than the state-of-arts while keeping the estimation accuracy approximately the same. The results have been published in <a href="./pdf/icdcs13.pdf"> <b>ICDCS 13</b> </a>.
</p>
</td>
</tr>
</table>
-->


<table class="table-project">
<col align="left" />
<col align="right" />

<tr>
<td>
<h2>Using Humans as Sensors: The Uncertain Data Provenance Challenge</h2> <br>
<p style="font-size:18px;">
The explosive growth in social network content suggests that the largest "sensor network" yet might be <i> human </i>. Extending the social sensing model, this project explores the prospect of utilizing social networks as sensor networks, which gives rise to an interesting <i> reliable sensing </i> problem. From a networked sensing standpoint, what makes this sensing problem formulation different is that, in the case of human participants, not only is the reliability of sources usually unknown but also the original data provenance may be uncertain. Individuals may report observations made by others as their own. The contribution of this project lies in developing a model that considers the impact of such information sharing on the analytical foundations of reliable sensing, and embed it into our tool <i> Apollo </i> that uses Twitter as a "sensor network" for observing events in the physical world. Evaluation, using Twitter-based case-studies, shows good correspondence between observations deemed correct by Apollo and ground truth. The results have been published in </a> <a href="./pdf/ipsn14.pdf"> <b>ACM/IEEE IPSN 14</b> </a>, <a href="./pdf/ipsn16.pdf"> <b>ACM/IEEE IPSN 16</b>.
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/humansensor.jpeg", alt="RT",  width="320" height="220" /> </td>
</tr>
</table>

<br>

<table class="table-project">
<col align="left" />
<col align="right" />

<tr>
<td>
<h2>Provenance-assisted Classification in Social Networks</h2> <br>
<p style="font-size:18px;">
Signal feature extraction and classification are two common tasks in the signal processing literature. This project investigates the use of source identities as a common mechanism for enhancing the classification accuracy of <i> social signals </i>. We define social signals as outputs, such as microblog entries, geotags, or uploaded images, contributed by users in a social network. While the design of such classifiers is application-specific, social signals share in common one key property: they are augmented by the explicit identity of the source. This motivates investigating whether or not knowing the source of each signal allows the classification accuracy to be improved. We call it <i> provenance-assisted </i> classification. This project answers the above question affirmatively, demonstrating how source identities can improve classification accuracy, and derives confidence bounds to quantify the accuracy of results. Evaluation is performed in two real-world contexts: (i) fact-finding that classifies microblog entries into true and false, and (ii) language classification of tweets issued by a set of possibly multi-lingual speakers. The results show that provenance features significantly improve classification accuracy of social signals. This observation offers a general mechanism for enhancing classification results in social networks.  The results of this work are going to appear in <a href="./pdf/jstsp14.pdf"> <b>  IEEE J-STSP 14 </b> </a>.
</p>
</td>
</tr>

<tr>  
<td><img class="center-fit" src="./pic/social-signal.jpeg", alt="RT",  width="320" height="250" /> </td>
</tr>
</table>

<!--

<hr />
<a name="systems"> <h2>Tool and Demo</h2> </a>


<p style="font-size:18px;">

Our research work also generated a reliable information distillation tool called <b> Apollo </b> that is used to summarize the flow of important events that are fundamentally changing our world and lives (e.g., Egyptian uprising, Japanese nuclear disaster, Hurricane Sandy, Boston Marathon Explosion etc.).  Apollo was demoed to very high-level army personnel (e.g., Mr. Gary Martin, the Executive Deputy to the Commanding General, Dr. Thomas Russell, the Director of Army Research Lab), as well as the United States Army Intelligence and Security Command (INSCOM). Apollo was selected as one of very few top showcases of the Network Science Collaborative Technology Alliance founded by the U.S. Army Research Laboratory (ARL) in 2011, 2012, and 2013. Now Apollo is now used by different branches at ARL. 

</p>

<h2>
 <a href="http://apollo.cse.nd.edu/index.html" target="_blank">Apollo-Inoformation Distillation Tool for Social (Human-Centric) Sensing</a>
</h2>
-->
<br>
<br>
<br>

                        
                    </div><!--//page-row-->
                    
                </div><!--//page-content-->
            </div><!--//page--> 
        </div><!--//content-->
    </div><!--//wrapper-->
    <!-- ******FOOTER****** --> 
    
    
      <footer class="footer">
        <div class="footer-content">
            <div class="container">
                <div class="row">
                <div class="footer-col col-lg-3 col-md-4 col-12 about">
                    <div class="footer-col-inner">
                        <h3>About</h3>
                        <ul>
                            <li><a href="index.html"><i class="fas fa-caret-right"></i>Home</a></li>
                            <li><a href="team.html"><i class="fas fa-caret-right"></i>People</a></li>
                            <li><a href="projects.html"><i class="fas fa-caret-right"></i>Research</a></li>
                            <li><a href="publications.html"><i class="fas fa-caret-right"></i>Publication</a></li>
                        </ul>
                    </div><!--//footer-col-inner-->
                </div><!--//foooter-col-->
                <div class="footer-col col-lg-6 col-md-8 col-12 newsletter">
                    <div class="footer-col-inner">
                        <h3>Join our mailing list</h3>
                        <p>Subscribe to get our weekly newsletter delivered directly to your inbox</p>
                        <form class="subscribe-form">
                            <div class="form-group">
                                <input type="email" class="form-control" placeholder="Enter your email" />
                            </div>
                            <input class="btn btn-theme btn-subscribe" type="submit" value="Subscribe">
                        </form>
                    </div><!--//footer-col-inner-->
                </div><!--//foooter-col--> 
                <div class="footer-col col-lg-3 col-12 contact">
                    <div class="footer-col-inner">
                        <h3>Contact us</h3>
                        <div class="row">
                            <p class="adr clearfix col-lg-12 col-md-4 col-12">
                                <i class="fas fa-map-marker-alt float-left"></i>        
                                <span class="adr-group float-left">       
                                    <span class="street-address">222 Cushing Hall</span><br>
                                    <span class="region">Department of Computer Science and Engineering</span><br>
                                    <span class="postal-code">Notre Dame, Indiana, 46556</span><br>
                                    <span class="country-name">USA</span>
                                </span>
                            </p>
                            <p class="email col-lg-12 col-md-4 col-12"><i class="fas fa-envelope"></i><a href="#">dwang5@nd.edu</a></p>  
                        </div> 
                    </div><!--//footer-col-inner-->            
                </div><!--//foooter-col-->   
                </div>   
            </div>        
        </div><!--//footer-content-->
        <div class="bottom-bar">
            <div class="container">
                <div class="row">
                    <small class="copyright col-lg-6 col-12"> Copyright @ <a href="#">SSLAB 2020</a></small>
                    <ul class="social float-right col-lg-6 col-12">
                        <li><a href="#" ><i class="fab fa-twitter"></i></a></li>
                        <li><a href="#" ><i class="fab fa-facebook-f"></i></a></li>
                        <li><a href="#" ><i class="fab fa-youtube"></i></a></li>
                        <li><a href="#" ><i class="fab fa-linkedin-in"></i></a></li>
                        <li><a href="#" ><i class="fab fa-google-plus-g"></i></a></li>
                        <li><a href="#" ><i class="fab fa-pinterest"></i></a></li>
                        <li><a href="#" ><i class="fab fa-skype"></i></a></li> 
                        <li class="row-end"><a href="#" ><i class="fas fa-rss"></i></a></li>
                    </ul><!--//social-->
                </div><!--//row-->
            </div><!--//container-->
        </div><!--//bottom-bar-->
    </footer><!--//footer-->
    



    <!-- Javascript -->          
    <script type="text/javascript" src="assets/plugins/jquery-3.3.1.min.js"></script>
    <script type="text/javascript" src="assets/plugins/popper.min.js"></script> 
    <script type="text/javascript" src="assets/plugins/bootstrap/js/bootstrap.min.js"></script> 
    <script type="text/javascript" src="assets/plugins/back-to-top.js"></script>
    <script type="text/javascript" src="assets/plugins/flexslider/jquery.flexslider-min.js"></script>
    <script type="text/javascript" src="assets/plugins/jflickrfeed/jflickrfeed.min.js"></script> 
    <script type="text/javascript" src="assets/js/main.js"></script>    
    
    <!-- Theme Switcher (REMOVE ON YOUR PRODUCTION SITE) -->
    <script type="text/javascript" src="assets/js/demo/theme-switcher.js"></script> 
    
</body>
</html>	

